{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "機器學習常犯錯的十件事.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeVDr0E5cg9p"
      },
      "source": [
        "# 機器學習常犯錯的十件事\n",
        "\n",
        "- 資料面\n",
        "  - 資料收集與處理不當\n",
        "  - 訓練集與測試集的類別分佈不一致\n",
        "  - 沒有資料視覺化的習慣\n",
        "  - 使用 LabelEcoder 為特徵編碼\n",
        "  - 資料處理不當導致資料洩漏\n",
        "\n",
        "\n",
        "- 模型面\n",
        "  - 僅使用測試集評估模型好壞\n",
        "  - 在沒有交叉驗證的情況下判斷模型性能\n",
        "  - 分類問題僅使用準確率作為衡量模型的指標\n",
        "  - 迴歸問題僅使用 R2 分數評估模型好壞\n",
        "  - 任何事情別急著想用 AI 解決\n",
        "\n",
        "> 詳細內容請[參閱](https://ithelp.ithome.com.tw/articles/10279778)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKJ7REAAc7fZ"
      },
      "source": [
        "## 2. 訓練集與測試集的類別分佈不一致\n",
        "在分類的資料中，初學者常見的錯誤是忘記使用分層抽樣 (stratify) 來對訓練集和測試集進行切割。當測試集的分佈盡可能與訓練相同情況下，模型才更有可能得到更準確的預測。然而在分類的問題中，我們必須更關注每個類別的資料分佈比例。以下舉個例子：假設我們有三個標籤的類別，而這三個類別的分佈比例分別為 4:3:3。同理我們在進行資料切割的時候必須確保訓練集與測試集需要有相同的資料分佈比例。\n",
        "\n",
        "大家應該都使用過 Sklearn 的 `train_test_split` 進行資料切割。在此方法中 Sklearn 提供了一個 `stratify` 參數達到分層隨機抽樣的目的。特別是在原始數據中樣本標籤分佈不均衡時非常有用，一些分類問題可能會在目標類的分佈中表現出很大的不平衡：例如，負樣本與正樣本比例懸殊(信用卡盜刷預測、離職員工預測)。以下用紅酒分類預測來進行示範，首先我們不使用 `stratify` 隨機切割資料並查看資料切割前後的三種類別比例。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAu0CkEEcfni",
        "outputId": "c49de79a-661f-4849-d61d-27fb0dca23cf"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "\n",
        "# 查看全部資料三種類別比例\n",
        "pd.Series(y).value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.398876\n",
              "0    0.331461\n",
              "2    0.269663\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3O1t6Sjcnmi",
        "outputId": "b0a99420-033a-4c74-d442-668b834a4d4e"
      },
      "source": [
        "# 實驗一: 不使用 stratify 進行切割資料\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.25)\n",
        "\n",
        "# 查看訓練集三種類別比例\n",
        "print('訓練集')\n",
        "print(pd.Series(y_train).value_counts(normalize=True))\n",
        "# 查看測試集三種類別比例\n",
        "print('測試集')\n",
        "print(pd.Series(y_test).value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練集\n",
            "1    0.386364\n",
            "0    0.363636\n",
            "2    0.250000\n",
            "dtype: float64\n",
            "測試集\n",
            "1    0.402985\n",
            "0    0.320896\n",
            "2    0.276119\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xndiXTJEdcoa"
      },
      "source": [
        "從上面切出來的訓練集與測試集可以發現三個類別的資料分佈比例都不同。因此我們可以使用 `stratify` 參數再切割一次。我們可以發現將 `stratify` 設置為目標 (y) 在訓練和測試集中產生相同的分佈。因為改變的類別的比例是一個嚴重的問題，可能會使模型更偏向於特定的類別。因此訓練資料的分佈必須要與實際情況越接近越好。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6UKRQJ5dHNX",
        "outputId": "c4c7398f-33cb-4bf1-9065-db7fd41f9cb4"
      },
      "source": [
        "# 實驗二: 使用 stratify 進行切割資料\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.25, stratify=y)\n",
        "\n",
        "# 查看訓練集三種類別比例\n",
        "print('訓練集')\n",
        "print(pd.Series(y_train).value_counts(normalize=True))\n",
        "# 查看測試集三種類別比例\n",
        "print('測試集')\n",
        "print(pd.Series(y_test).value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練集\n",
            "1    0.386364\n",
            "0    0.340909\n",
            "2    0.272727\n",
            "dtype: float64\n",
            "測試集\n",
            "1    0.402985\n",
            "0    0.328358\n",
            "2    0.268657\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u5t_VqIHp28"
      },
      "source": [
        "## 4. 使用 LabelEncoder 為特徵編碼\n",
        "通常我們要為類別的特徵進行編碼，直覺會想到 Sklearn 的 [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)。但是如果一個資料集中有多個特徵是屬於類別型的資料，豈不是很麻煩?必須要一個一個呼叫 LabelEncoder 分別為這些特徵進行轉換。如果你看到這邊有同感的，在這裡要告訴你事實並非如此！我們看看 在官方文件下 LabelEncoder 的描述：\n",
        "\n",
        "> This transformer should be used to encode target values, i.e. y, and not the input X.\n",
        "\n",
        "簡單來說 LabelEncoder 只是被用來編碼輸出項 y 而已的！你還在用它來編碼你的每個 x 嗎？（暈\n",
        "\n",
        "那麼我們該用什麼方法來編碼有順序的類別特徵呢？如果你仔細閱讀有關編碼分類特徵的 Sklearn 用戶指南，你會看到它清楚地說明：\n",
        "\n",
        "> To convert categorical features to integer codes, we can use the OrdinalEncoder. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1)\n",
        "\n",
        "看到這邊大家應該知道閱讀官方文件的重要性吧！官方文件中建議 x 項的輸入特徵可以採用 [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) 一次為所有特徵依序做 Label Encoding。OrdinalEncoder 編碼器的使用方式如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww97x8Q_Zy8v",
        "outputId": "6d6ac4b1-3af5-47d1-f0d0-b1274585d529"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "enc = OrdinalEncoder()\n",
        "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
        "enc.fit(X)\n",
        "\n",
        "print(enc.categories_)\n",
        "# 測試編碼\n",
        "enc.transform([['Female', 3], ['Male', 1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 2.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT1SgV_QHu2u"
      },
      "source": [
        "以上的範例是 X 有三筆資料，每筆資料都有兩個特徵。我們可以發現第一個特徵是性別 Male 與 Female，因此 OrdinalEncoder 會依造字母開頭做排序 Female 編碼為 0 而 Male 編碼為 1。另外第二個特徵為數字 1、2、3，同理依序為他們編碼成 0、1、2。只需閱讀官方文檔和用戶指南，你就可以了解很多關於 Sklearn 的知識！是不是很棒～\n",
        "\n",
        "> 可以自行調整順序 categories=[['Male','Female'],[3,2,1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vFsN4V6mUt2"
      },
      "source": [
        "## 5. 資料處理不當導致資料洩漏\n",
        "最簡單的解決辦法，就是不要使用 `fit()` 一次轉換所有的資料。在做任何資料轉換之前要先確保訓練集與測試集已經完整地被切開。即使切開後也不要再拿測試集呼叫 `fit()` 或 `fit_transform()`，這一樣會導致相同問題發生。因為訓練集和測試集必須進行相同的轉換，依照官方的範例我們必須先使用 `fit_transform()` 在訓練集上進行擬合與轉換。這確保了轉換器僅從訓練集學習，從中找出參數例如平均值與變異數並同時對其進行變換。接著使用 `transform()` 方法在測試資料上進行轉換，根據從訓練數據中學到的訊息進行轉換。\n",
        "\n",
        "\n",
        "### 不建議方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFSrehninAxQ"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, random_state=44)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXSoRF7_nJaQ",
        "outputId": "26f24e12-b647-4720-a7c6-e0494d39834e"
      },
      "source": [
        "print('\\nStandardScaler 縮放過後訓練集的最小值 : ', X_scaled.min(axis=0))\n",
        "print('StandardScaler 縮放過後訓練集的最大值 : ', X_scaled.max(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "StandardScaler 縮放過後訓練集的最小值 :  [0. 0. 0. 0.]\n",
            "StandardScaler 縮放過後訓練集的最大值 :  [1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQz69Ix4q1tD"
      },
      "source": [
        "![](https://i.imgur.com/9AhNggd.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZKCuUzxqILV"
      },
      "source": [
        "### 建議方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do6070V7JjBC"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=44)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLbfods4mbYW",
        "outputId": "68b3b50e-49c3-474a-f36e-506524bd9f8b"
      },
      "source": [
        "print('\\nStandardScaler 縮放過後訓練集的最小值 : ', X_train_scaled.min(axis=0))\n",
        "print('StandardScaler 縮放過後訓練集的最大值 : ', X_train_scaled.max(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "StandardScaler 縮放過後訓練集的最小值 :  [0. 0. 0. 0.]\n",
            "StandardScaler 縮放過後訓練集的最大值 :  [1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3cnyAxXopPU",
        "outputId": "09d65049-2435-4520-d516-51e2672fd4d2"
      },
      "source": [
        "print('\\nStandardScaler 縮放過後測試集的最小值 : ', X_test_scaled.min(axis=0))\n",
        "print('StandardScaler 縮放過後測試集的最大值 : ', X_test_scaled.max(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "StandardScaler 縮放過後測試集的最小值 :  [ 0.02777778 -0.09090909 -0.01785714  0.        ]\n",
            "StandardScaler 縮放過後測試集的最大值 :  [0.94444444 0.86363636 1.03571429 0.95833333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KenvW_fro3a_"
      },
      "source": [
        "![](https://i.imgur.com/GXoqZg2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3a-eJ3JTg62"
      },
      "source": [
        "## 8. 分類問題僅使用準確率作為衡量模型的指標\n",
        "對於多元類分類的問題更是應該注意你的模型評估指標。如果達到 80% 的準確率，是否意味著模型在預測類別1、類別2、類別3甚至所有類時一樣準確呢？一般的準確率永遠無法回答此類問題，但幸運的是其他分類指標提供了更多的訊息指標。它就是[混淆矩陣](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)(confusion matrix)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp3x48ozosuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ac5ab2-a254-4576-c267-c439c1d782c7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_true = [2, 0, 2, 2, 0, 1, 1]\n",
        "y_pred = [0, 0, 2, 2, 0, 2, 1]\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0]\n",
            " [0 1 1]\n",
            " [1 0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4YcjG7MTr0G",
        "outputId": "12209edc-2a26-476e-f6a0-0feb84448dac"
      },
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.67      0.67      0.67         3\n",
            "\n",
            "    accuracy                           0.71         7\n",
            "   macro avg       0.78      0.72      0.71         7\n",
            "weighted avg       0.76      0.71      0.70         7\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arktNfqxWpI0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}